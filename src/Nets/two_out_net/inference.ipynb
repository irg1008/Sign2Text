{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencia de red ResNet para clasificación de signo a texto.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Índice.\n",
    "\n",
    "- [Configuración](#configuración)\n",
    "  - [Configuración de la red](#configuración-de-la-red)\n",
    "- [Elección del model a inferir](#elección-del-model-a-inferir)\n",
    "  - [Carga del modelo](#carga-del-modelo)\n",
    "- [Inferencia](#inferencia)\n",
    "  - [Por webcam](#por-webcam)\n",
    "  - [Por archivo](#desde-archivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ivan\\Documents\\Projects\\TFG\\ubu-sign2text\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from config.const import *\n",
    "from config.torch_config import get_transform\n",
    "from config.dataset import get_dataset_path\n",
    "from lib.video_dataset import VideoFrameDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración de la red\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [\"WLASL/videos\", \"actions/frames\"]\n",
    "MODELS_NAME = [\"WLASL_5\", \"actions_small\"]\n",
    "\n",
    "index = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path, model_path = get_dataset_path(dataset=DATASETS[index], model_name=MODELS_NAME[index])\n",
    "multiple_transform = get_transform(IMAGE_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoFrameDataset(\n",
    "    root_path=data_path,\n",
    "    transform=multiple_transform,\n",
    "    num_segments=NUM_SEGMENTS,\n",
    "    frames_per_segment=FRAMES_PER_SEGMENT,\n",
    "    image_size=IMAGE_SIZE,\n",
    ")\n",
    "\n",
    "classes = dataset.classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elección del modelo a inferir\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import load, onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga del modelo onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(model_path.replace(\".pth\", \".onnx\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencia\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from common.inference import video_webcam_inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ivan\\Documents\\Projects\\TFG\\ubu-sign2text\\src\\nets\\two_out_net\\inference.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/two_out_net/inference.ipynb#ch0000015?line=0'>1</a>\u001b[0m video_webcam_inference(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/two_out_net/inference.ipynb#ch0000015?line=1'>2</a>\u001b[0m     model,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/two_out_net/inference.ipynb#ch0000015?line=2'>3</a>\u001b[0m     classes,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/two_out_net/inference.ipynb#ch0000015?line=3'>4</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/two_out_net/inference.ipynb#ch0000015?line=4'>5</a>\u001b[0m     multiple_transform,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/two_out_net/inference.ipynb#ch0000015?line=5'>6</a>\u001b[0m     fps_interval\u001b[39m=\u001b[39;49mNUM_SEGMENTS \u001b[39m*\u001b[39;49m FRAMES_PER_SEGMENT,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/two_out_net/inference.ipynb#ch0000015?line=6'>7</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\Documents\\Projects\\TFG\\ubu-sign2text\\src\\nets\\two_out_net\\..\\common\\inference.py:97\u001b[0m, in \u001b[0;36mvideo_webcam_inference\u001b[1;34m(model, classes, device, transform, fps_interval)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/two_out_net/../common/inference.py?line=85'>86</a>\u001b[0m     cv2\u001b[39m.\u001b[39mputText(\n\u001b[0;32m     <a href='file:///c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/two_out_net/../common/inference.py?line=86'>87</a>\u001b[0m         frame,\n\u001b[0;32m     <a href='file:///c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/two_out_net/../common/inference.py?line=87'>88</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabel\u001b[39m}\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m{\u001b[39;00mscore\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/two_out_net/../common/inference.py?line=92'>93</a>\u001b[0m         \u001b[39m2\u001b[39m,\n\u001b[0;32m     <a href='file:///c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/two_out_net/../common/inference.py?line=93'>94</a>\u001b[0m     )\n\u001b[0;32m     <a href='file:///c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/two_out_net/../common/inference.py?line=95'>96</a>\u001b[0m \u001b[39m# cv2.rectangle(frame, (400, 150), (900, 550), (250, 0, 0), 2)\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/two_out_net/../common/inference.py?line=96'>97</a>\u001b[0m cv2\u001b[39m.\u001b[39;49mimshow(\u001b[39m\"\u001b[39;49m\u001b[39mASL SIGN DETECTER\u001b[39;49m\u001b[39m\"\u001b[39;49m, frame)\n\u001b[0;32m     <a href='file:///c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/two_out_net/../common/inference.py?line=98'>99</a>\u001b[0m \u001b[39mif\u001b[39;00m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m1\u001b[39m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mq\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/two_out_net/../common/inference.py?line=99'>100</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "video_webcam_inference(\n",
    "    model,\n",
    "    classes,\n",
    "    \"cuda\",\n",
    "    multiple_transform,\n",
    "    fps_interval=NUM_SEGMENTS * FRAMES_PER_SEGMENT,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f994aa240b7f2e467b44197a4d9955597ae42523f807a2e4bab019e4d9f67af"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
