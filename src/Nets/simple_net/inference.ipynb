{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencia de red ResNet para clasificación de signo a texto.\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Índice.\n",
    "\n",
    "- [Configuración](#configuración)\n",
    "  - [Configuración de la red](#configuración-de-la-red)\n",
    "- [Elección del model a inferir](#elección-del-model-a-inferir)\n",
    "  - [Carga del modelo](#carga-del-modelo)\n",
    "- [Inferencia](#inferencia)\n",
    "  - [Por webcam](#por-webcam)\n",
    "  - [Por archivo](#desde-archivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ivan\\Documents\\Projects\\TFG\\ubu-sign2text\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from config.const import *\n",
    "from config.torch_config import get_transform\n",
    "from config.dataset import get_dataset_path\n",
    "from lib.video_dataset import VideoFrameDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración de la red\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = [\"WLASL/videos\", \"actions/frames\"]\n",
    "MODELS_NAME = [\"WLASL\", \"actions_small\"]\n",
    "\n",
    "index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path, model_path = get_dataset_path(\n",
    "    dataset=DATASETS[index], model_name=MODELS_NAME[index]\n",
    ")\n",
    "multiple_transform = get_transform(IMAGE_SIZE, IMAGE_RANDOM_CROP_RESIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] El sistema no puede encontrar la ruta especificada: 'c:\\\\Users\\\\Ivan\\\\Documents\\\\Projects\\\\TFG\\\\ubu-sign2text\\\\data\\\\actions\\\\frames'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ivan\\Documents\\Projects\\TFG\\ubu-sign2text\\src\\nets\\simple_net\\inference.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/simple_net/inference.ipynb#ch0000007?line=0'>1</a>\u001b[0m dataset \u001b[39m=\u001b[39m VideoFrameDataset(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/simple_net/inference.ipynb#ch0000007?line=1'>2</a>\u001b[0m     root_path\u001b[39m=\u001b[39;49mdata_path,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/simple_net/inference.ipynb#ch0000007?line=2'>3</a>\u001b[0m     transform\u001b[39m=\u001b[39;49mmultiple_transform,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/simple_net/inference.ipynb#ch0000007?line=3'>4</a>\u001b[0m     num_segments\u001b[39m=\u001b[39;49mNUM_SEGMENTS,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/simple_net/inference.ipynb#ch0000007?line=4'>5</a>\u001b[0m     frames_per_segment\u001b[39m=\u001b[39;49mFRAMES_PER_SEGMENT,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/simple_net/inference.ipynb#ch0000007?line=5'>6</a>\u001b[0m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ivan/Documents/Projects/TFG/ubu-sign2text/src/nets/simple_net/inference.ipynb#ch0000007?line=7'>8</a>\u001b[0m classes \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mclasses\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\Documents\\Projects\\TFG\\ubu-sign2text\\src\\nets\\simple_net\\lib\\video_dataset.py:64\u001b[0m, in \u001b[0;36mVideoFrameDataset.__init__\u001b[1;34m(self, root_path, transform, num_segments, frames_per_segment, imagefile_template)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframes_per_segment \u001b[39m=\u001b[39m frames_per_segment\n\u001b[0;32m     63\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimagefile_template \u001b[39m=\u001b[39m imagefile_template\n\u001b[1;32m---> 64\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_data(root_path)\n",
      "File \u001b[1;32mc:\\Users\\Ivan\\Documents\\Projects\\TFG\\ubu-sign2text\\src\\nets\\simple_net\\lib\\video_dataset.py:69\u001b[0m, in \u001b[0;36mVideoFrameDataset._load_data\u001b[1;34m(self, root_path)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39m\"\"\"Load the video data.\"\"\"\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvideos: List[VideoRecord] \u001b[39m=\u001b[39m []\n\u001b[1;32m---> 69\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses \u001b[39m=\u001b[39m listdir(root_path)\n\u001b[0;32m     70\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses)))\n\u001b[0;32m     72\u001b[0m \u001b[39mfor\u001b[39;00m target, label \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] El sistema no puede encontrar la ruta especificada: 'c:\\\\Users\\\\Ivan\\\\Documents\\\\Projects\\\\TFG\\\\ubu-sign2text\\\\data\\\\actions\\\\frames'"
     ]
    }
   ],
   "source": [
    "dataset = VideoFrameDataset(\n",
    "    root_path=data_path,\n",
    "    transform=multiple_transform,\n",
    "    num_segments=NUM_SEGMENTS,\n",
    "    frames_per_segment=FRAMES_PER_SEGMENT,\n",
    ")\n",
    "\n",
    "classes = dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elección del modelo a inferir\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'd:\\\\Proyectos\\\\TFG\\\\Sign2Text\\\\Project\\\\models\\\\actions_small.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Proyectos\\TFG\\Sign2Text\\Project\\src\\nets\\simple_net\\inference.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Proyectos/TFG/Sign2Text/Project/src/nets/simple_net/inference.ipynb#ch0000011?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m load(model_path)\n",
      "File \u001b[1;32md:\\Proyectos\\TFG\\Sign2Text\\Project\\venv\\lib\\site-packages\\torch\\serialization.py:594\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=590'>591</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=591'>592</a>\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=593'>594</a>\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=594'>595</a>\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=595'>596</a>\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=596'>597</a>\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=597'>598</a>\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=598'>599</a>\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[1;32md:\\Proyectos\\TFG\\Sign2Text\\Project\\venv\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=227'>228</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=228'>229</a>\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=229'>230</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=230'>231</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=231'>232</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[1;32md:\\Proyectos\\TFG\\Sign2Text\\Project\\venv\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=209'>210</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=210'>211</a>\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'd:\\\\Proyectos\\\\TFG\\\\Sign2Text\\\\Project\\\\models\\\\actions_small.pth'"
     ]
    }
   ],
   "source": [
    "model = load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencia\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from common.inference import video_webcam_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (64x1x1x1). Calculated output size: (64x1x0x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\Proyectos\\TFG\\Sign2Text\\Project\\src\\nets\\SimpleNet\\inference.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Proyectos/TFG/Sign2Text/Project/src/nets/SimpleNet/inference.ipynb#ch0000015?line=0'>1</a>\u001b[0m video_webcam_inference(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Proyectos/TFG/Sign2Text/Project/src/nets/SimpleNet/inference.ipynb#ch0000015?line=1'>2</a>\u001b[0m     model,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Proyectos/TFG/Sign2Text/Project/src/nets/SimpleNet/inference.ipynb#ch0000015?line=2'>3</a>\u001b[0m     classes,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Proyectos/TFG/Sign2Text/Project/src/nets/SimpleNet/inference.ipynb#ch0000015?line=3'>4</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Proyectos/TFG/Sign2Text/Project/src/nets/SimpleNet/inference.ipynb#ch0000015?line=4'>5</a>\u001b[0m     multiple_transform,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Proyectos/TFG/Sign2Text/Project/src/nets/SimpleNet/inference.ipynb#ch0000015?line=5'>6</a>\u001b[0m     fps_interval\u001b[39m=\u001b[39;49mNUM_SEGMENTS \u001b[39m*\u001b[39;49m FRAMES_PER_SEGMENT,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Proyectos/TFG/Sign2Text/Project/src/nets/SimpleNet/inference.ipynb#ch0000015?line=6'>7</a>\u001b[0m )\n",
      "File \u001b[1;32md:\\Proyectos\\TFG\\Sign2Text\\Project\\src\\nets\\SimpleNet\\..\\common\\inference.py:78\u001b[0m, in \u001b[0;36mvideo_webcam_inference\u001b[1;34m(model, classes, device, transform, fps_interval)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/src/nets/SimpleNet/../common/inference.py?line=75'>76</a>\u001b[0m \u001b[39mif\u001b[39;00m fps \u001b[39m%\u001b[39m fps_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m fps \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/src/nets/SimpleNet/../common/inference.py?line=76'>77</a>\u001b[0m     transformed_video \u001b[39m=\u001b[39m preprocess(video, device, transform)\n\u001b[1;32m---> <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/src/nets/SimpleNet/../common/inference.py?line=77'>78</a>\u001b[0m     scores \u001b[39m=\u001b[39m model(transformed_video)\n\u001b[0;32m     <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/src/nets/SimpleNet/../common/inference.py?line=78'>79</a>\u001b[0m     first_five \u001b[39m=\u001b[39m argmax(scores, classes)\n\u001b[0;32m     <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/src/nets/SimpleNet/../common/inference.py?line=79'>80</a>\u001b[0m     video \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32md:\\Proyectos\\TFG\\Sign2Text\\Project\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Proyectos\\TFG\\Sign2Text\\Project\\src\\nets\\SimpleNet\\lib\\simple_model.py:77\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/src/nets/SimpleNet/lib/simple_model.py?line=73'>74</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mIn - \u001b[39m\u001b[39m\"\u001b[39m, x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/src/nets/SimpleNet/lib/simple_model.py?line=75'>76</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assign(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1, \u001b[39m\"\u001b[39m\u001b[39mconv1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/src/nets/SimpleNet/lib/simple_model.py?line=76'>77</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_assign(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2, \u001b[39m\"\u001b[39;49m\u001b[39mconv2\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/src/nets/SimpleNet/lib/simple_model.py?line=78'>79</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/src/nets/SimpleNet/lib/simple_model.py?line=79'>80</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDEBUG:\n",
      "File \u001b[1;32md:\\Proyectos\\TFG\\Sign2Text\\Project\\src\\nets\\SimpleNet\\lib\\simple_model.py:67\u001b[0m, in \u001b[0;36mCNN._assign\u001b[1;34m(self, x, fn, name)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/src/nets/SimpleNet/lib/simple_model.py?line=65'>66</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_assign\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor, fn: Callable[[Tensor], Tensor], name: \u001b[39mstr\u001b[39m):\n\u001b[1;32m---> <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/src/nets/SimpleNet/lib/simple_model.py?line=66'>67</a>\u001b[0m     out \u001b[39m=\u001b[39m fn(x)\n\u001b[0;32m     <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/src/nets/SimpleNet/lib/simple_model.py?line=67'>68</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDEBUG:\n\u001b[0;32m     <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/src/nets/SimpleNet/lib/simple_model.py?line=68'>69</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m{\u001b[39;00mout\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Proyectos\\TFG\\Sign2Text\\Project\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Proyectos\\TFG\\Sign2Text\\Project\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32md:\\Proyectos\\TFG\\Sign2Text\\Project\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Proyectos\\TFG\\Sign2Text\\Project\\venv\\lib\\site-packages\\torch\\nn\\modules\\pooling.py:240\u001b[0m, in \u001b[0;36mMaxPool3d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/pooling.py?line=238'>239</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/pooling.py?line=239'>240</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmax_pool3d(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/pooling.py?line=240'>241</a>\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mceil_mode,\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/modules/pooling.py?line=241'>242</a>\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_indices)\n",
      "File \u001b[1;32md:\\Proyectos\\TFG\\Sign2Text\\Project\\venv\\lib\\site-packages\\torch\\_jit_internal.py:422\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/_jit_internal.py?line=419'>420</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m if_true(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/_jit_internal.py?line=420'>421</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/_jit_internal.py?line=421'>422</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m if_false(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Proyectos\\TFG\\Sign2Text\\Project\\venv\\lib\\site-packages\\torch\\nn\\functional.py:785\u001b[0m, in \u001b[0;36m_max_pool3d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/functional.py?line=782'>783</a>\u001b[0m \u001b[39mif\u001b[39;00m stride \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/functional.py?line=783'>784</a>\u001b[0m     stride \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mannotate(List[\u001b[39mint\u001b[39m], [])\n\u001b[1;32m--> <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/nn/functional.py?line=784'>785</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mmax_pool3d(\u001b[39minput\u001b[39;49m, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given input size: (64x1x1x1). Calculated output size: (64x1x0x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "video_webcam_inference(\n",
    "    model,\n",
    "    classes,\n",
    "    \"cuda\",\n",
    "    multiple_transform,\n",
    "    fps_interval=NUM_SEGMENTS * FRAMES_PER_SEGMENT,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f256e947ed30eec6960a657ce8e0e10d9b747cc7764d264741e6353e53d381f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
