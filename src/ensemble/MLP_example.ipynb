{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook vamos a usar [esta libreria de ensamblado](https://github.com/TorchEnsemble-Community/Ensemble-Pytorch) para intentar mejorar el acc de neustro modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pequeño test antes de cargar el modelo grande"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este ejemplo está extraido de la siguiente guía: https://ensemble-pytorch.readthedocs.io/en/latest/quick_start.html#set-the-logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Base Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(147456, 128)\n",
    "        self.linear2 = nn.Linear(128, 128)\n",
    "        self.linear3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, data):\n",
    "        data = data.view(data.size(0), -1)  # flatten\n",
    "        output = F.relu(self.linear1(data))\n",
    "        output = F.relu(self.linear2(output))\n",
    "        output = self.linear3(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log will be saved in 'd:\\Proyectos\\TFG\\Sign2Text\\Project\\src\\ensemble\\logs'.\n",
      "Start logging into file d:\\Proyectos\\TFG\\Sign2Text\\Project\\src\\ensemble\\logs\\classification_mnist_mlp-2022_04_01_19_07.log...\n"
     ]
    }
   ],
   "source": [
    "from torchensemble.utils.logging import set_logger\n",
    "\n",
    "logger = set_logger(\"classification_mnist_mlp\")\n",
    "\n",
    "\n",
    "# Descomentar esto para usar tensorboard.\n",
    "# logger = set_logger(\"classification_mnist_mlp\", use_tb_logger=True)\n",
    "# Usar \"tensorboard --logdir=logs/\" para ver los logs en la consola (https://www.tensorflow.org/tensorboard)\n",
    "# Más info de tensorboard con PyTorch aquí: https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchensemble import VotingClassifier\n",
    "\n",
    "model = VotingClassifier(\n",
    "    estimator=MLP,\n",
    "    n_estimators=10,\n",
    "    cuda=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "model.set_criterion(criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Optimizer ans Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_optimizer(\n",
    "    \"Adam\",  # parameter optimizer\n",
    "    lr=1e-3,  # learning rate of the optimizer\n",
    "    weight_decay=5e-4,\n",
    ")  # weight decay of the optimizer\n",
    "\n",
    "# model.set_scheduler(\n",
    "#     \"\",  # scheduler\n",
    "#     mode=\"min\",  # mode of the scheduler\n",
    "#     factor=0.5,  # factor of the scheduler\n",
    "#     patience=5,  # patience of the scheduler\n",
    "# )  # verbose of the scheduler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get loader for trainning and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../\")\n",
    "\n",
    "from nets.ResNet.utils.loader import get_dataset, split_dataset\n",
    "from nets.ResNet.config.torch_config import get_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = get_transform(image_size=128, width_multiplier=3)\n",
    "data_path = \"../../data/WLASL/frames_5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, classes = get_dataset(data_path, transform)\n",
    "train_loader, test_loader = split_dataset(dataset, train_split=0.7, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model export src.\n",
    "src = \"../../models/example_ensemble\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 000 | Batch: 000 | Loss: 2.28855 | Correct: 1/16\n",
      "Estimator: 001 | Epoch: 000 | Batch: 000 | Loss: 2.27660 | Correct: 6/16\n",
      "Estimator: 002 | Epoch: 000 | Batch: 000 | Loss: 2.30829 | Correct: 2/16\n",
      "Estimator: 003 | Epoch: 000 | Batch: 000 | Loss: 2.26127 | Correct: 8/16\n",
      "Estimator: 004 | Epoch: 000 | Batch: 000 | Loss: 2.30542 | Correct: 5/16\n",
      "Estimator: 005 | Epoch: 000 | Batch: 000 | Loss: 2.25813 | Correct: 1/16\n",
      "Estimator: 006 | Epoch: 000 | Batch: 000 | Loss: 2.32737 | Correct: 0/16\n",
      "Estimator: 007 | Epoch: 000 | Batch: 000 | Loss: 2.27499 | Correct: 3/16\n",
      "Estimator: 008 | Epoch: 000 | Batch: 000 | Loss: 2.29777 | Correct: 4/16\n",
      "Estimator: 009 | Epoch: 000 | Batch: 000 | Loss: 2.37391 | Correct: 2/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 19:07:31,656 - INFO: Saving the model to `../../models/example_ensemble\\VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-04-01 19:07:34,134 - INFO: Epoch: 000 | Validation Acc: 33.333 % | Historical Best: 33.333 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 001 | Batch: 000 | Loss: 3.23469 | Correct: 7/16\n",
      "Estimator: 001 | Epoch: 001 | Batch: 000 | Loss: 14.69904 | Correct: 5/16\n",
      "Estimator: 002 | Epoch: 001 | Batch: 000 | Loss: 9.14375 | Correct: 5/16\n",
      "Estimator: 003 | Epoch: 001 | Batch: 000 | Loss: 17.22717 | Correct: 4/16\n",
      "Estimator: 004 | Epoch: 001 | Batch: 000 | Loss: 2.91366 | Correct: 4/16\n",
      "Estimator: 005 | Epoch: 001 | Batch: 000 | Loss: 8.24148 | Correct: 3/16\n",
      "Estimator: 006 | Epoch: 001 | Batch: 000 | Loss: 5.48035 | Correct: 2/16\n",
      "Estimator: 007 | Epoch: 001 | Batch: 000 | Loss: 2.07989 | Correct: 7/16\n",
      "Estimator: 008 | Epoch: 001 | Batch: 000 | Loss: 5.31751 | Correct: 4/16\n",
      "Estimator: 009 | Epoch: 001 | Batch: 000 | Loss: 14.30182 | Correct: 3/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 19:07:58,011 - INFO: Epoch: 001 | Validation Acc: 20.833 % | Historical Best: 33.333 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 002 | Batch: 000 | Loss: 5.83547 | Correct: 4/16\n",
      "Estimator: 001 | Epoch: 002 | Batch: 000 | Loss: 1.66842 | Correct: 7/16\n",
      "Estimator: 002 | Epoch: 002 | Batch: 000 | Loss: 3.92579 | Correct: 5/16\n",
      "Estimator: 003 | Epoch: 002 | Batch: 000 | Loss: 3.68235 | Correct: 7/16\n",
      "Estimator: 004 | Epoch: 002 | Batch: 000 | Loss: 3.64320 | Correct: 6/16\n",
      "Estimator: 005 | Epoch: 002 | Batch: 000 | Loss: 6.55105 | Correct: 3/16\n",
      "Estimator: 006 | Epoch: 002 | Batch: 000 | Loss: 4.56637 | Correct: 3/16\n",
      "Estimator: 007 | Epoch: 002 | Batch: 000 | Loss: 2.35551 | Correct: 6/16\n",
      "Estimator: 008 | Epoch: 002 | Batch: 000 | Loss: 2.14081 | Correct: 7/16\n",
      "Estimator: 009 | Epoch: 002 | Batch: 000 | Loss: 6.30049 | Correct: 5/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 19:08:22,099 - INFO: Saving the model to `../../models/example_ensemble\\VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-04-01 19:08:24,624 - INFO: Epoch: 002 | Validation Acc: 39.583 % | Historical Best: 39.583 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 003 | Batch: 000 | Loss: 2.65145 | Correct: 8/16\n",
      "Estimator: 001 | Epoch: 003 | Batch: 000 | Loss: 1.61118 | Correct: 10/16\n",
      "Estimator: 002 | Epoch: 003 | Batch: 000 | Loss: 1.57629 | Correct: 8/16\n",
      "Estimator: 003 | Epoch: 003 | Batch: 000 | Loss: 1.90706 | Correct: 8/16\n",
      "Estimator: 004 | Epoch: 003 | Batch: 000 | Loss: 3.75634 | Correct: 4/16\n",
      "Estimator: 005 | Epoch: 003 | Batch: 000 | Loss: 1.77593 | Correct: 6/16\n",
      "Estimator: 006 | Epoch: 003 | Batch: 000 | Loss: 1.10715 | Correct: 9/16\n",
      "Estimator: 007 | Epoch: 003 | Batch: 000 | Loss: 1.37085 | Correct: 10/16\n",
      "Estimator: 008 | Epoch: 003 | Batch: 000 | Loss: 2.08909 | Correct: 11/16\n",
      "Estimator: 009 | Epoch: 003 | Batch: 000 | Loss: 1.67135 | Correct: 9/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 19:08:48,527 - INFO: Epoch: 003 | Validation Acc: 39.583 % | Historical Best: 39.583 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 004 | Batch: 000 | Loss: 0.83584 | Correct: 11/16\n",
      "Estimator: 001 | Epoch: 004 | Batch: 000 | Loss: 1.16270 | Correct: 12/16\n",
      "Estimator: 002 | Epoch: 004 | Batch: 000 | Loss: 2.31077 | Correct: 9/16\n",
      "Estimator: 003 | Epoch: 004 | Batch: 000 | Loss: 1.13174 | Correct: 10/16\n",
      "Estimator: 004 | Epoch: 004 | Batch: 000 | Loss: 1.13245 | Correct: 9/16\n",
      "Estimator: 005 | Epoch: 004 | Batch: 000 | Loss: 2.43273 | Correct: 5/16\n",
      "Estimator: 006 | Epoch: 004 | Batch: 000 | Loss: 1.63092 | Correct: 6/16\n",
      "Estimator: 007 | Epoch: 004 | Batch: 000 | Loss: 1.25966 | Correct: 9/16\n",
      "Estimator: 008 | Epoch: 004 | Batch: 000 | Loss: 2.05776 | Correct: 8/16\n",
      "Estimator: 009 | Epoch: 004 | Batch: 000 | Loss: 1.59479 | Correct: 9/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 19:09:12,746 - INFO: Saving the model to `../../models/example_ensemble\\VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-04-01 19:09:15,248 - INFO: Epoch: 004 | Validation Acc: 45.833 % | Historical Best: 45.833 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 005 | Batch: 000 | Loss: 0.90594 | Correct: 10/16\n",
      "Estimator: 001 | Epoch: 005 | Batch: 000 | Loss: 0.54403 | Correct: 12/16\n",
      "Estimator: 002 | Epoch: 005 | Batch: 000 | Loss: 1.91800 | Correct: 7/16\n",
      "Estimator: 003 | Epoch: 005 | Batch: 000 | Loss: 0.98279 | Correct: 10/16\n",
      "Estimator: 004 | Epoch: 005 | Batch: 000 | Loss: 1.56919 | Correct: 7/16\n",
      "Estimator: 005 | Epoch: 005 | Batch: 000 | Loss: 2.12808 | Correct: 6/16\n",
      "Estimator: 006 | Epoch: 005 | Batch: 000 | Loss: 0.94837 | Correct: 12/16\n",
      "Estimator: 007 | Epoch: 005 | Batch: 000 | Loss: 0.79747 | Correct: 12/16\n",
      "Estimator: 008 | Epoch: 005 | Batch: 000 | Loss: 0.89912 | Correct: 11/16\n",
      "Estimator: 009 | Epoch: 005 | Batch: 000 | Loss: 1.35495 | Correct: 9/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 19:09:39,247 - INFO: Epoch: 005 | Validation Acc: 39.583 % | Historical Best: 45.833 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 006 | Batch: 000 | Loss: 1.46837 | Correct: 8/16\n",
      "Estimator: 001 | Epoch: 006 | Batch: 000 | Loss: 1.70086 | Correct: 11/16\n",
      "Estimator: 002 | Epoch: 006 | Batch: 000 | Loss: 0.81828 | Correct: 12/16\n",
      "Estimator: 003 | Epoch: 006 | Batch: 000 | Loss: 0.47096 | Correct: 13/16\n",
      "Estimator: 004 | Epoch: 006 | Batch: 000 | Loss: 0.48956 | Correct: 12/16\n",
      "Estimator: 005 | Epoch: 006 | Batch: 000 | Loss: 0.74730 | Correct: 13/16\n",
      "Estimator: 006 | Epoch: 006 | Batch: 000 | Loss: 0.53182 | Correct: 13/16\n",
      "Estimator: 007 | Epoch: 006 | Batch: 000 | Loss: 1.30136 | Correct: 10/16\n",
      "Estimator: 008 | Epoch: 006 | Batch: 000 | Loss: 1.78230 | Correct: 10/16\n",
      "Estimator: 009 | Epoch: 006 | Batch: 000 | Loss: 0.58179 | Correct: 10/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 19:10:03,475 - INFO: Epoch: 006 | Validation Acc: 45.833 % | Historical Best: 45.833 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 007 | Batch: 000 | Loss: 1.16302 | Correct: 12/16\n",
      "Estimator: 001 | Epoch: 007 | Batch: 000 | Loss: 0.26112 | Correct: 15/16\n",
      "Estimator: 002 | Epoch: 007 | Batch: 000 | Loss: 0.66485 | Correct: 12/16\n",
      "Estimator: 003 | Epoch: 007 | Batch: 000 | Loss: 1.47650 | Correct: 8/16\n",
      "Estimator: 004 | Epoch: 007 | Batch: 000 | Loss: 0.36805 | Correct: 15/16\n",
      "Estimator: 005 | Epoch: 007 | Batch: 000 | Loss: 0.65475 | Correct: 13/16\n",
      "Estimator: 006 | Epoch: 007 | Batch: 000 | Loss: 0.74412 | Correct: 10/16\n",
      "Estimator: 007 | Epoch: 007 | Batch: 000 | Loss: 1.64380 | Correct: 9/16\n",
      "Estimator: 008 | Epoch: 007 | Batch: 000 | Loss: 1.35827 | Correct: 10/16\n",
      "Estimator: 009 | Epoch: 007 | Batch: 000 | Loss: 0.96551 | Correct: 11/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 19:10:27,709 - INFO: Saving the model to `../../models/example_ensemble\\VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-04-01 19:10:30,238 - INFO: Epoch: 007 | Validation Acc: 47.917 % | Historical Best: 47.917 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 008 | Batch: 000 | Loss: 1.72127 | Correct: 6/16\n",
      "Estimator: 001 | Epoch: 008 | Batch: 000 | Loss: 1.90234 | Correct: 11/16\n",
      "Estimator: 002 | Epoch: 008 | Batch: 000 | Loss: 0.56952 | Correct: 12/16\n",
      "Estimator: 003 | Epoch: 008 | Batch: 000 | Loss: 0.63004 | Correct: 13/16\n",
      "Estimator: 004 | Epoch: 008 | Batch: 000 | Loss: 0.72294 | Correct: 12/16\n",
      "Estimator: 005 | Epoch: 008 | Batch: 000 | Loss: 0.75213 | Correct: 11/16\n",
      "Estimator: 006 | Epoch: 008 | Batch: 000 | Loss: 0.54727 | Correct: 12/16\n",
      "Estimator: 007 | Epoch: 008 | Batch: 000 | Loss: 0.51831 | Correct: 12/16\n",
      "Estimator: 008 | Epoch: 008 | Batch: 000 | Loss: 0.66444 | Correct: 11/16\n",
      "Estimator: 009 | Epoch: 008 | Batch: 000 | Loss: 0.61125 | Correct: 11/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 19:10:54,106 - INFO: Epoch: 008 | Validation Acc: 45.833 % | Historical Best: 47.917 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 009 | Batch: 000 | Loss: 1.46803 | Correct: 10/16\n",
      "Estimator: 001 | Epoch: 009 | Batch: 000 | Loss: 0.57372 | Correct: 13/16\n",
      "Estimator: 002 | Epoch: 009 | Batch: 000 | Loss: 0.63017 | Correct: 11/16\n",
      "Estimator: 003 | Epoch: 009 | Batch: 000 | Loss: 0.63386 | Correct: 13/16\n",
      "Estimator: 004 | Epoch: 009 | Batch: 000 | Loss: 0.56623 | Correct: 12/16\n",
      "Estimator: 005 | Epoch: 009 | Batch: 000 | Loss: 0.42939 | Correct: 15/16\n",
      "Estimator: 006 | Epoch: 009 | Batch: 000 | Loss: 0.60449 | Correct: 11/16\n",
      "Estimator: 007 | Epoch: 009 | Batch: 000 | Loss: 0.93971 | Correct: 10/16\n",
      "Estimator: 008 | Epoch: 009 | Batch: 000 | Loss: 0.87095 | Correct: 8/16\n",
      "Estimator: 009 | Epoch: 009 | Batch: 000 | Loss: 1.58542 | Correct: 11/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 19:11:18,338 - INFO: Epoch: 009 | Validation Acc: 45.833 % | Historical Best: 47.917 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 010 | Batch: 000 | Loss: 1.21135 | Correct: 10/16\n",
      "Estimator: 001 | Epoch: 010 | Batch: 000 | Loss: 0.40995 | Correct: 13/16\n",
      "Estimator: 002 | Epoch: 010 | Batch: 000 | Loss: 0.23984 | Correct: 14/16\n",
      "Estimator: 003 | Epoch: 010 | Batch: 000 | Loss: 0.18846 | Correct: 15/16\n",
      "Estimator: 004 | Epoch: 010 | Batch: 000 | Loss: 0.62387 | Correct: 13/16\n",
      "Estimator: 005 | Epoch: 010 | Batch: 000 | Loss: 1.11112 | Correct: 10/16\n",
      "Estimator: 006 | Epoch: 010 | Batch: 000 | Loss: 0.47495 | Correct: 13/16\n",
      "Estimator: 007 | Epoch: 010 | Batch: 000 | Loss: 0.69481 | Correct: 12/16\n",
      "Estimator: 008 | Epoch: 010 | Batch: 000 | Loss: 0.40554 | Correct: 14/16\n",
      "Estimator: 009 | Epoch: 010 | Batch: 000 | Loss: 1.16407 | Correct: 11/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 19:11:34,564 - INFO: Epoch: 010 | Validation Acc: 47.917 % | Historical Best: 47.917 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 011 | Batch: 000 | Loss: 0.41030 | Correct: 14/16\n",
      "Estimator: 001 | Epoch: 011 | Batch: 000 | Loss: 0.57998 | Correct: 14/16\n",
      "Estimator: 002 | Epoch: 011 | Batch: 000 | Loss: 0.20219 | Correct: 16/16\n",
      "Estimator: 003 | Epoch: 011 | Batch: 000 | Loss: 0.88693 | Correct: 11/16\n",
      "Estimator: 004 | Epoch: 011 | Batch: 000 | Loss: 0.38722 | Correct: 14/16\n",
      "Estimator: 005 | Epoch: 011 | Batch: 000 | Loss: 0.96605 | Correct: 10/16\n",
      "Estimator: 006 | Epoch: 011 | Batch: 000 | Loss: 0.44061 | Correct: 14/16\n",
      "Estimator: 007 | Epoch: 011 | Batch: 000 | Loss: 0.33453 | Correct: 13/16\n",
      "Estimator: 008 | Epoch: 011 | Batch: 000 | Loss: 0.26824 | Correct: 15/16\n",
      "Estimator: 009 | Epoch: 011 | Batch: 000 | Loss: 0.55414 | Correct: 13/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 19:11:48,673 - INFO: Saving the model to `../../models/example_ensemble\\VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-04-01 19:11:50,000 - INFO: Epoch: 011 | Validation Acc: 50.000 % | Historical Best: 50.000 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 012 | Batch: 000 | Loss: 0.48130 | Correct: 13/16\n",
      "Estimator: 001 | Epoch: 012 | Batch: 000 | Loss: 0.10445 | Correct: 16/16\n",
      "Estimator: 002 | Epoch: 012 | Batch: 000 | Loss: 0.49071 | Correct: 12/16\n",
      "Estimator: 003 | Epoch: 012 | Batch: 000 | Loss: 0.97883 | Correct: 8/16\n",
      "Estimator: 004 | Epoch: 012 | Batch: 000 | Loss: 0.59158 | Correct: 13/16\n",
      "Estimator: 005 | Epoch: 012 | Batch: 000 | Loss: 0.31332 | Correct: 14/16\n",
      "Estimator: 006 | Epoch: 012 | Batch: 000 | Loss: 0.19565 | Correct: 16/16\n",
      "Estimator: 007 | Epoch: 012 | Batch: 000 | Loss: 0.31905 | Correct: 14/16\n",
      "Estimator: 008 | Epoch: 012 | Batch: 000 | Loss: 0.31631 | Correct: 14/16\n",
      "Estimator: 009 | Epoch: 012 | Batch: 000 | Loss: 0.28492 | Correct: 15/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 19:12:04,228 - INFO: Epoch: 012 | Validation Acc: 47.917 % | Historical Best: 50.000 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 013 | Batch: 000 | Loss: 0.61747 | Correct: 11/16\n",
      "Estimator: 001 | Epoch: 013 | Batch: 000 | Loss: 0.43645 | Correct: 14/16\n",
      "Estimator: 002 | Epoch: 013 | Batch: 000 | Loss: 0.54707 | Correct: 12/16\n",
      "Estimator: 003 | Epoch: 013 | Batch: 000 | Loss: 0.36883 | Correct: 14/16\n",
      "Estimator: 004 | Epoch: 013 | Batch: 000 | Loss: 0.32328 | Correct: 15/16\n",
      "Estimator: 005 | Epoch: 013 | Batch: 000 | Loss: 0.42992 | Correct: 12/16\n",
      "Estimator: 006 | Epoch: 013 | Batch: 000 | Loss: 0.49069 | Correct: 14/16\n",
      "Estimator: 007 | Epoch: 013 | Batch: 000 | Loss: 0.21792 | Correct: 15/16\n",
      "Estimator: 008 | Epoch: 013 | Batch: 000 | Loss: 0.36504 | Correct: 13/16\n",
      "Estimator: 009 | Epoch: 013 | Batch: 000 | Loss: 0.44643 | Correct: 14/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 19:12:18,196 - INFO: Epoch: 013 | Validation Acc: 45.833 % | Historical Best: 50.000 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 014 | Batch: 000 | Loss: 0.27504 | Correct: 14/16\n",
      "Estimator: 001 | Epoch: 014 | Batch: 000 | Loss: 0.21036 | Correct: 14/16\n",
      "Estimator: 002 | Epoch: 014 | Batch: 000 | Loss: 0.40948 | Correct: 14/16\n",
      "Estimator: 003 | Epoch: 014 | Batch: 000 | Loss: 0.70202 | Correct: 12/16\n",
      "Estimator: 004 | Epoch: 014 | Batch: 000 | Loss: 0.26005 | Correct: 16/16\n",
      "Estimator: 005 | Epoch: 014 | Batch: 000 | Loss: 0.23347 | Correct: 15/16\n",
      "Estimator: 006 | Epoch: 014 | Batch: 000 | Loss: 0.28479 | Correct: 15/16\n",
      "Estimator: 007 | Epoch: 014 | Batch: 000 | Loss: 0.20159 | Correct: 16/16\n",
      "Estimator: 008 | Epoch: 014 | Batch: 000 | Loss: 0.45146 | Correct: 13/16\n",
      "Estimator: 009 | Epoch: 014 | Batch: 000 | Loss: 0.15595 | Correct: 16/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 19:12:32,368 - INFO: Epoch: 014 | Validation Acc: 45.833 % | Historical Best: 50.000 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 015 | Batch: 000 | Loss: 0.20945 | Correct: 15/16\n",
      "Estimator: 001 | Epoch: 015 | Batch: 000 | Loss: 0.32386 | Correct: 14/16\n",
      "Estimator: 002 | Epoch: 015 | Batch: 000 | Loss: 0.12506 | Correct: 15/16\n",
      "Estimator: 003 | Epoch: 015 | Batch: 000 | Loss: 0.33335 | Correct: 15/16\n",
      "Estimator: 004 | Epoch: 015 | Batch: 000 | Loss: 0.24745 | Correct: 15/16\n",
      "Estimator: 005 | Epoch: 015 | Batch: 000 | Loss: 0.22270 | Correct: 15/16\n",
      "Estimator: 006 | Epoch: 015 | Batch: 000 | Loss: 0.96022 | Correct: 11/16\n",
      "Estimator: 007 | Epoch: 015 | Batch: 000 | Loss: 0.07651 | Correct: 16/16\n",
      "Estimator: 008 | Epoch: 015 | Batch: 000 | Loss: 0.19835 | Correct: 16/16\n",
      "Estimator: 009 | Epoch: 015 | Batch: 000 | Loss: 0.66000 | Correct: 12/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 19:12:46,445 - INFO: Saving the model to `../../models/example_ensemble\\VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-04-01 19:12:47,787 - INFO: Epoch: 015 | Validation Acc: 52.083 % | Historical Best: 52.083 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 016 | Batch: 000 | Loss: 0.17185 | Correct: 16/16\n",
      "Estimator: 001 | Epoch: 016 | Batch: 000 | Loss: 0.15513 | Correct: 15/16\n",
      "Estimator: 002 | Epoch: 016 | Batch: 000 | Loss: 0.22027 | Correct: 15/16\n",
      "Estimator: 003 | Epoch: 016 | Batch: 000 | Loss: 0.18653 | Correct: 15/16\n",
      "Estimator: 004 | Epoch: 016 | Batch: 000 | Loss: 0.29525 | Correct: 14/16\n",
      "Estimator: 005 | Epoch: 016 | Batch: 000 | Loss: 0.23360 | Correct: 15/16\n",
      "Estimator: 006 | Epoch: 016 | Batch: 000 | Loss: 0.32536 | Correct: 13/16\n",
      "Estimator: 007 | Epoch: 016 | Batch: 000 | Loss: 0.11007 | Correct: 16/16\n",
      "Estimator: 008 | Epoch: 016 | Batch: 000 | Loss: 0.19266 | Correct: 16/16\n",
      "Estimator: 009 | Epoch: 016 | Batch: 000 | Loss: 0.09403 | Correct: 16/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 19:13:01,915 - INFO: Saving the model to `../../models/example_ensemble\\VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-04-01 19:13:03,259 - INFO: Epoch: 016 | Validation Acc: 54.167 % | Historical Best: 54.167 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 017 | Batch: 000 | Loss: 0.10278 | Correct: 16/16\n",
      "Estimator: 001 | Epoch: 017 | Batch: 000 | Loss: 0.10669 | Correct: 16/16\n",
      "Estimator: 002 | Epoch: 017 | Batch: 000 | Loss: 0.09586 | Correct: 16/16\n",
      "Estimator: 003 | Epoch: 017 | Batch: 000 | Loss: 0.16740 | Correct: 16/16\n",
      "Estimator: 004 | Epoch: 017 | Batch: 000 | Loss: 0.06716 | Correct: 16/16\n",
      "Estimator: 005 | Epoch: 017 | Batch: 000 | Loss: 0.20538 | Correct: 16/16\n",
      "Estimator: 006 | Epoch: 017 | Batch: 000 | Loss: 0.33882 | Correct: 13/16\n",
      "Estimator: 007 | Epoch: 017 | Batch: 000 | Loss: 0.10779 | Correct: 16/16\n",
      "Estimator: 008 | Epoch: 017 | Batch: 000 | Loss: 0.30893 | Correct: 15/16\n",
      "Estimator: 009 | Epoch: 017 | Batch: 000 | Loss: 0.25051 | Correct: 15/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 19:13:17,555 - INFO: Epoch: 017 | Validation Acc: 50.000 % | Historical Best: 54.167 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 018 | Batch: 000 | Loss: 0.10211 | Correct: 16/16\n",
      "Estimator: 001 | Epoch: 018 | Batch: 000 | Loss: 0.05276 | Correct: 16/16\n",
      "Estimator: 002 | Epoch: 018 | Batch: 000 | Loss: 0.15264 | Correct: 15/16\n",
      "Estimator: 003 | Epoch: 018 | Batch: 000 | Loss: 0.15951 | Correct: 16/16\n",
      "Estimator: 004 | Epoch: 018 | Batch: 000 | Loss: 0.07595 | Correct: 16/16\n",
      "Estimator: 005 | Epoch: 018 | Batch: 000 | Loss: 0.18957 | Correct: 15/16\n",
      "Estimator: 006 | Epoch: 018 | Batch: 000 | Loss: 0.24462 | Correct: 15/16\n",
      "Estimator: 007 | Epoch: 018 | Batch: 000 | Loss: 0.06568 | Correct: 16/16\n",
      "Estimator: 008 | Epoch: 018 | Batch: 000 | Loss: 0.52121 | Correct: 12/16\n",
      "Estimator: 009 | Epoch: 018 | Batch: 000 | Loss: 0.53325 | Correct: 11/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 19:13:31,708 - INFO: Epoch: 018 | Validation Acc: 50.000 % | Historical Best: 54.167 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 019 | Batch: 000 | Loss: 0.06232 | Correct: 16/16\n",
      "Estimator: 001 | Epoch: 019 | Batch: 000 | Loss: 0.13283 | Correct: 16/16\n",
      "Estimator: 002 | Epoch: 019 | Batch: 000 | Loss: 0.10777 | Correct: 15/16\n",
      "Estimator: 003 | Epoch: 019 | Batch: 000 | Loss: 0.14707 | Correct: 16/16\n",
      "Estimator: 004 | Epoch: 019 | Batch: 000 | Loss: 0.11351 | Correct: 16/16\n",
      "Estimator: 005 | Epoch: 019 | Batch: 000 | Loss: 0.24712 | Correct: 14/16\n",
      "Estimator: 006 | Epoch: 019 | Batch: 000 | Loss: 0.44734 | Correct: 13/16\n",
      "Estimator: 007 | Epoch: 019 | Batch: 000 | Loss: 0.06410 | Correct: 16/16\n",
      "Estimator: 008 | Epoch: 019 | Batch: 000 | Loss: 0.10992 | Correct: 16/16\n",
      "Estimator: 009 | Epoch: 019 | Batch: 000 | Loss: 0.53289 | Correct: 14/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 19:13:45,779 - INFO: Epoch: 019 | Validation Acc: 54.167 % | Historical Best: 54.167 %\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    epochs=20,\n",
    "    save_model=True,\n",
    "    save_dir=src,  # training data\n",
    ")  # the number of training epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.166666666666664\n"
     ]
    }
   ],
   "source": [
    "# Evaluating\n",
    "\n",
    "accuracy = model.evaluate(test_loader)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../models/example_ensemble/VotingClassifier_MLP_10_ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Proyectos\\TFG\\Sign2Text\\Project\\src\\ensemble\\MLP_example.ipynb Cell 24'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Proyectos/TFG/Sign2Text/Project/src/ensemble/MLP_example.ipynb#ch0000023?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchensemble\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m io\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Proyectos/TFG/Sign2Text/Project/src/ensemble/MLP_example.ipynb#ch0000023?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m load\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Proyectos/TFG/Sign2Text/Project/src/ensemble/MLP_example.ipynb#ch0000023?line=3'>4</a>\u001b[0m loaded_model \u001b[39m=\u001b[39m load(src \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m/VotingClassifier_MLP_10_ckpt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Proyectos\\TFG\\Sign2Text\\Project\\venv\\lib\\site-packages\\torch\\serialization.py:594\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=590'>591</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=591'>592</a>\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=593'>594</a>\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=594'>595</a>\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=595'>596</a>\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=596'>597</a>\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=597'>598</a>\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=598'>599</a>\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[1;32md:\\Proyectos\\TFG\\Sign2Text\\Project\\venv\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=227'>228</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=228'>229</a>\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=229'>230</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=230'>231</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=231'>232</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[1;32md:\\Proyectos\\TFG\\Sign2Text\\Project\\venv\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=209'>210</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> <a href='file:///d%3A/Proyectos/TFG/Sign2Text/Project/venv/lib/site-packages/torch/serialization.py?line=210'>211</a>\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../models/example_ensemble/VotingClassifier_MLP_10_ckpt'"
     ]
    }
   ],
   "source": [
    "from torchensemble.utils import io\n",
    "\n",
    "io.load(model, save_dir=src, logger=logger)  # reload\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "66fbc5ca68b17436878331c7d6f57fc7c2a0d60f6d6bab6b896fa750f025e76d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
