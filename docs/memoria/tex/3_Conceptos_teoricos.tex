\capitulo{3}{Conceptos teóricos}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Este proyecto es un proyecto de \loc{machine learning}. Dentro del \loc{machine learning}, es de aprendizaje supervisado. Más concretamente intenta resolver un problema de clasificación mediante deep learning. Las redes neuronales aplicadas para la clasificación serán \loc{ResNets} y \sigla{CNN} (\loc{Convolutional Neural Networks}). Veamos en detalle todos estos terminos en los siguientes apartados.

\section{Machine Learning}

Según Tom Mitchell \cite{mitchell1997machine}, un programa de ordenador aprende de una experiencia \textit{E} con respecto a alguna tarea \textit{T} si su medida de desempeño \textit{P} (del inglés \loc{performance}) mejora con E.

El uso del machine learning se origina en la búsqueda de soluciones a problemas que no podemos resolver programáticamente. Determinar las soluciones se centra en la recogida y análisis de datos con la finalidad de buscar relaciones entre ellos.

Para aclarar este concepto, veamos un ejemplo:
Imaginemos que debemos estimar el precio de un coche usado pero no tenemos la fórmula exacta para valorar su estado. Lo que si sabemos es que el precio del coche aumenta y disminuye dependiendo de sus propiedades, como la marca, el kilometraje, o el desgaste. No sabemos tampoco cuales de las propiedades tiene más importancia. Sabemos seguro que cuantos más kilómetros tenga el coche, menor será su precio, pero no sabemos a que escala ocurre esto.

Para determinar la solución necesitamos estudiar el precio de coches en el mercado y anotar sus características. Estos datos son los que daremos a nuestro programa para que busque las relaciones entre propiedades e indique el precio óptimo de los coches.

Saliendo del ejemplo, el machine learning se divide en distintos tipos según la cantidad de datos (o supervisión) que otorgamos a nuestro programa.

\subsection{Unsupervised Learning}

El \loc{unsupervised learning} o  aprendizaje no supervisado, tiene su principal característica, en que no necesita una muestra de datos para aprender.

\subsection{Semi-supervised Learning}

\subsection{Supervised Learning}

\subsubsection{Regression}

\subsubsection{Classification}

\begin{enumerate}
  \item Redes Neuronales

        \begin{itemize}
          \item \loc{Perceptron}
          \item \loc{Feedforward neural network}
          \item \loc{Backpropagation}
          \item \loc{Recurrent neural network}
          \item \loc{Convolutional neural network}
          \item \loc{Autoencoder}
        \end{itemize}

\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Carga de datos}

\subsection{Extracción de frames de videos}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Tratamiento de los datos}

\subsection{Normalización}

\subsection{\loc{Data Augmentation}}

\subsection{Transformación de datos a tensores}

\subsection{\loc{Batching}}

\subsection{\loc{Subsampling}}

\subsection{Eliminación de datos innecesarios}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Red Neuronal ResNet}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Estructura de la red convolucional}

\subsection{Capas convolucionales}

\subsubsection{\loc{Downsampling}}
\subsubsection{\loc{MaxPooling}}
\subsubsection{\loc{BatchNormalization}}

\subsection{\loc{Flatten layer}}

\subsection{\loc{Dense layers}}

\subsubsection{\loc{Dropout}}

\subsection{\loc{Lineal layers}}

\subsubsection{\loc{Leaky ReLU}}
\subsubsection{\loc{ReLU}}

\subsection{\loc{Capas de salida}}

\subsubsection{Sigmoide}
\subsubsection{Softmax}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Entrenamiento e hiperparametrización}

\subsection{\loc{Pipeline} del proceo}

\subsection{\loc{Optimizer}}

\subsection{\loc{Scheduler}}

\subsection{\loc{Criterion}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Salida de la red}

\subsection{Dos salidas en la misma red}

\subsubsection{Las salidas se controlan entre ellas}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Comprobación de resultados}

¿Cómo podemos saber si el resultado incorrecto se debe a la estructura de la red o a los datos introducidos?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Exportación del modelo}

\subsection{Formatos estándares}

\subsubsection{\sigla{ONNX}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Copresión del modelo}

\subsection{Consecuencias}

\subsubsection{Velocidad}

\subsubsection{\loc{Accuracy}}

\subsection{Métodos de compresión}

\subsubsection{\loc{Quantization}}

\subsubsection{\loc{Prunning}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Estudio de escalabilidad del modelo}

Vamos a comprobar hasta que punto la red neuronal es capaz de mantener la precisión de clasificación con el aumento de las etiquetas. Para todo lo anterior el número de etiquetas a clasificar han sido 8. Vamos a aumentar esto hasta 100 etiquetas.

En la siguiente tabla blabla