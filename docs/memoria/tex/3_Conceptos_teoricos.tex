\capitulo{3}{Conceptos teóricos}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Este proyecto es un proyecto de \loc{machine learning}. Dentro del \loc{machine learning}, es de aprendizaje supervisado. Más concretamente intenta resolver un problema de clasificación mediante \loc{deep learning}. Las redes neuronales aplicadas para la clasificación serán \sigla{CNN} (\loc{Convolutional Neural Networks}), y \loc{ResNets}, una arquitectura sobre las \sigla{CNN}. Veamos en detalle todos estos términos en los siguientes apartados.

\section{Machine Learning}

Según Tom Mitchell \bib{mitchell1997machine}, un programa de ordenador aprende de una experiencia \textit{E} con respecto a alguna tarea \textit{T} si su medida de desempeño \textit{P} (del inglés \loc{performance}) mejora con la experiencia E.

El uso del machine learning se origina en la búsqueda de soluciones a problemas que no podemos resolver programáticamente. Determinar las soluciones se centra en la recogida y análisis de datos\footnote{A lo largo del documento nos referiremos a los datos indistintamente como <<datos>> o <<instancias>>} con la finalidad de buscar relaciones entre ellos.

Para aclarar este concepto, veamos un ejemplo \bib{alpaydin2021machine}\label{example:car_price}:
Imaginemos que debemos estimar el precio de un coche usado pero no tenemos la fórmula exacta para valorar su estado. Lo que si sabemos es que el precio del coche aumenta y disminuye dependiendo de sus propiedades, como la marca, el kilometraje, o el desgaste. No sabemos tampoco cuales de las propiedades tienen más importancia. Sabemos seguro que cuantos más kilómetros tenga el coche, menor será su precio, pero no sabemos a que escala ocurre esto.

Para determinar la solución necesitamos estudiar el precio de coches en el mercado y anotar sus características. Estos datos son los que daremos a nuestro programa para que busque las relaciones entre propiedades e indique el precio óptimo de los coches.

Saliendo del ejemplo, el \loc{machine learning} se divide en distintos tipos según la cantidad de datos (o supervisión) que otorgamos al <<programa>>. Hay más formas de dividir el \loc{machine learning}, como puedes ver en \ref{fig:MachineLearningTypes} (nombraremos alguna de ella a lo largo de los siguientes apartados), pero nos vamos a centrar en \loc{supervised, unsupervised} y \loc{semi-supervised learning}.

\imagen{./img/memoria/conceptos/MachineLearningTypes}{Tipos de \loc{machine learning} según datos, inferencia estadística y técnicas de aprendizaje}{MachineLearningTypes}


\subsection{Unsupervised Learning}

El \loc{unsupervised learning} o  aprendizaje no supervisado, tiene su principal característica en que es capaz de detectar las relaciones entre los datos sin ayuda de etiquetas o respuestas externas. Si volvemos al ejemplo de los coches, seríamos capaces de determinar el precio de venta sin necesidad de recibir datos de coches reales.

La técnica principal en el aprendizaje no supervisado es el agrupamiento de los datos (o \loc{clustering}) según la similaridad de sus características.

\subsubsection{\loc{Clustering}}

El \loc{clustering} consiste en el agrupamiento de datos no etiquetados basándonos en sus similaridades o diferencias. Los algoritmos de \loc{clustering} son usados para procesar datos crudos sin alteraciones en grupos representados por patrones o estructuras de información. Estos algoritmos se pueden clasificar en:

\begin{itemize}
  \item \textbf{Mutuamente excluyentes}: En estos algoritmos se estipula que una instancia de datos solo puede existir en un y solo un \loc{cluster} (o grupo). Este tipo de \loc{clustering} también se denomina \loc{<<hard>> clustering}. Un ejemplo de algoritmo mutuamente excluyente es el algoritmo de \loc{K-means}. En \loc{K-means}, la <<K>> indica el número de \loc{clusters}  basándonos en su centroide\footnote{O centro geométrico, es la posición media aritmética entre todos los puntos de una figura}. Los puntos, representando a un dato, caerán en el grupo con el centroide más cercano. Un valor de \loc{K-means} mayor indicará un mayor número de agrupamientos. \imagen{./img/memoria/conceptos/Unsupervised_K-Means_Clustering_Algorithm}{Ejemplo de datos antes y después del \loc{clustering} para un algoritmo mutuamente excluyente \loc{K-means} \bib{sinaga2020unsupervised}.}{BeforeAfterClustering}

  \item \textbf{Superpuestos}: En el caso de los algoritmos superpuestos, la diferencia es que un dato puede pertenecer a más de un \loc{cluster} de forma simultánea con distinto grado de pertenencia. Un ejemplo de algoritmo superpuesto es el \loc{<<soft>> K-means}.

  \item \textbf{Jerárquicos}: También conocido como \sigla{HCA} (\loc{hierarchical cluster analysis}), es un algoritmo no supervisado que se puede categorizar de dos modos, en aglomerativo o divisivo. El primero funciona con acercamiento \loc{<<bottom-up>>}. Los datos comienzan de forma separada y se van uniendo de forma iterativa según similitud hasta conseguir un único \loc{cluster}. La similitud se puede medir de las siguientes formas:
        \begin{enumerate}
          \item Método de \loc{Ward}: La distancia entre dos \loc{clusters} se define por el aumento de la distancia cuadrática después de que los \loc{clusters} sean fusionados.
          \item Promedio de distancias: Este método usa la distancia media entre dos puntos en cada \loc{cluster}.
          \item Distancia máxima: La distancia usada es la distancia mayor entre dos puntos en distintos \loc{clusters}.
          \item Distancia mínima: Se define por la distancia mínima entre dos puntos de dos \loc{clusters} diferentes.
        \end{enumerate}
        La medida más común a la hora de calcular estas distancias es la distancia euclídea, aunque otra muy común en la literatura es la distancia \loc{Manhattan}.

        Por otro lado, el acercamiento divisivo, o \loc{<<top-down>>} funciona dividiendo un único \loc{cluster} basándose en las diferencias entre instancias (puntos del \loc{cluster}). Visualmente se parece a un dendrograma\footnote{Representación gráfica de datos en forma de árbol para organizar datos en categorías y subcategorías hasta alcanzar el nivel de detalle deseado}.

  \item \textbf{Probabilísticos}: En un algoritmo probabilístico, los puntos se agrupan basándose en la probabilidad de que pertenezcan a una distribución paramétrica \footnote{La estadística paramétrica es una rama de la estadística con la que se deciden valores basándose en distribuciones desconocidas. Estas se determinan según un número finito de parámetros.}. El \sigla{GMM} (\loc{Gaussian Mixture Model}) es el método más usado en \loc{clustereing} probabilístico.
        \begin{itemize}
          \item \loc{Gaussian Mixture Model}: Este algoritmo se clasifica como mixto debido a que se compone de un número no especificado de funciones de densidad probabilística. Normalmente se encargará de comprobar si un instancia es parte de una distribución Gaussiana o normal. El algoritmo más usado para determinar la distribución es el \sigla{E-M} (Expectation-Maximizarion) \bib{do2008expectation}.
        \end{itemize}
\end{itemize}

\subsubsection{Reglas de asociación}

Las reglas de asociación es un método que busca encontrar las relaciones entre variables de un \loc{dataset}. Suelen ser usados en \loc{marketing}, sistemas de recomendación, relación entre productos, estudio de hábitos de consumición \bib{panjaitan2019implementation}, entre otros. El algoritmo más usado en reglas de asociación es el algoritmo <<Apriori>>.

\begin{itemize}
  \item \textbf{Algoritmo Apriori}: Este algoritmo permite encontrar <<conjuntos de elementos frecuentes>>. Estos conjuntos sirven para generar reglas de asociación que permiten extender los \loc{sets} a \loc{sets} de mayor tamaño.

        \begin{algorithm}[H]
          \caption{Algoritmo Apriori}

          \BlankLine
          \KwIn{Para un \loc{dataset} $T$, un umbral de soporte $\varepsilon$ y un conjunto de datos $C_{k}$ para el nivel $k$}
          \BlankLine

          $L_1 \gets findFrequentOneItemsets(T)$\\
          $k \gets $2\\

          \BlankLine
          \While{$L_{k-1}$ not empty}{
            \tcc{Generación de Apriori}
            $C_k \gets \text{empty list}$\\
            \ForAll{$p \subseteq L\text{, } q \subseteq L $}{
              $c \gets p \cup q_{k-1}$\\

              \ForAll{$u \in L$}{
                \If{$u \subseteq c$}{
                  $C_k \gets C_k \cup \lbrace{c}\rbrace$\\
                }
              }
            }

            \BlankLine
            \tcc{Cálculo de candidatos}
            \For{$t \in T$}{
              $D_t \gets \lbrace c \in C_k : c \subseteq t\rbrace$\\
              \For{$c \in D_t$}{
                $count[c] \gets count[c] + 1$\\
              }
            }

            $k \gets k+1$\\
            $L_k \gets \lbrace c \in C_k : count[c] \geq \varepsilon \rbrace $\\
          }

          \BlankLine
          \Return{$Union\left(L_k\right)$}

        \end{algorithm}

\end{itemize}

\subsubsection{Reducción de la dimensionalidad}

Normalmente cuando disponemos de una mayor cantidad de datos, tendemos a obtener mejores soluciones, aunque esto tiene impacto en el rendimiento de nuestros algoritmos y puede dificultar comprender de forma completa nuestro \loc{dataset}.
La reducción de la dimensionalidad se usa cuando el número de características o dimensiones de un \loc{dataset} es muy grande. Reduce el número de instancias a un tamaño manejable manteniendo la integridad de los datos lo máximo posible\bib{sorzano2014survey}\bib{ghodsi2006dimensionality}. Algunos métodos de reducción de la dimensionalidad son: \sigla{PCA} (del inglés \loc{Principal Component Analysis}), \sigla{SVD} (\loc{Singular Value Decomposition}) y \loc{Autoencoders}.

\subsection{Semi-supervised Learning}

El aprendizaje semi-supervisado se caracteriza por tener la capacidad de aprender de conjuntos de datos cuyas instancias no están completamente etiquetadas. En nuestro ejemplo \ref{example:car_price}<<cálculo de precio de un coche según sus propiedades>>, tendríamos precios reales solo para algunos de los coches, mientras que otros no tendrían una etiqueta establecida.

La característica principal que diferencia el aprendizaje semi-supervisado del aprendizaje no supervisado y del aprendizaje supervisado (que veremos a continuación) es que la capacidad de aprender del algoritmo se nutre del hecho de que algunos datos no estén etiquetados. A la hora de intentar averiguar las etiquetas faltantes en base a las presentes, podemos observar comportamientos de aprendizaje que no se verían en los otros dos tipos de \loc{machine learning}.

De este modo, no es útil solo como algoritmo de aprendizaje si no como algoritmo de generación de nuevos datos en aprendizaje supervisado \bib{zhu2009introduction}. Si la obtención de datos y etiquetas nos supone un proceso costoso y/o el acceso a los datos es limitado \footnote{\pe: La recopilación de datos médicos es algo compleja, ya que se debe tener permiso del paciente, así como hay enfermedades cuyos datos son muy escasos y difíciles de conseguir.}, podemos crear un algoritmo de aprendizaje semi-supervisado para completar la falta de datos.

Algunos de los métodos usados en aprendizaje semi-supervisado son los siguientes:

\begin{itemize}
  \item \textbf{Modelos generativos}: Con este modelo se busca estimar $p(x \mid y)$, la distribución de los puntos pertenecientes a cada clase. La probabilidad $p(x \mid y)$ de que un punto $x$ pertenezca a una etiqueta $y$ es proporcional a $p(x \mid y) \cdot p(y)$ por la Regla de Bayes.

        Extrayéndolo de \bib{zhu2009introduction}, los modelos generativos asumen que las distribuciones tienen la forma $p(x \mid y, \theta)$ parametrizada por el vector $\theta$. Si esta suposición es incorrecta, los datos no etiquetados pueden incluso disminuir la capacidad de acierto de la solución. Pero, en el caso contrario, si la suposición es correcta, los datos etiquetados mejoraran el rendimiento del modelo.

        Los datos no etiquetados se suelen distribuir mediante una distribución Gaussiana mixta. La distribución de probabilidad conjunta se puede escribir como $p(x,y \mid \theta) = p(y \mid \theta) \cdot p(x \mid \theta)$ mediante el teorema de probabilidad compuesta. Cada vector $\theta$ se asocia con una función de decisión \[f_{\theta}(x) = \underset{x}{\argmax} p(y \mid x, \theta)\]

        El parámetro se elige entonces basándonos en la adaptación a los datos etiquetados y no etiquetados, usamos un peso de balanceo $\lambda$:

        \begin{equation*}
          \underset{\theta}{\argmax} \left( \log p\left(\left\{x_i, y_i\right\}_{i=1}^{l} \mid \theta\right)+\lambda \log p\left(\left\{x_i\right\}_{i=l+1}^{l+u} \mid \theta \right) \right)
        \end{equation*}

  \item \textbf{Modelos basados en grafos}: Este modelo asume un grafo $G = {V,E}$ tal que los vértices $V$ son las instancias de datos (etiquetados y no etiquetados) y $E$ las aristas no dirigidas que conectan las instancias $i,j$ con un peso $w_{ij}$ \bib{song2022graph}\bib{van2020survey}. La construcción de un grafo se cumple en los siguientes pasos. Podemos ver estos pasos en la figura \ref{fig:SSLTaxonomy}:
        \begin{enumerate}
          \item \textbf{Construcción del grafo}: Se suele asumir una instanciación inicial del grafo aleatoria
          \item \textbf{\loc{Weighting}}: Cálculo de pesos de los datos etiquetados para la fase de inferencia.
          \item \textbf{Inferencia de etiquetas}: La tarea a cumplir aquí es propagar información de las instancias etiquetadas a las <<no etiquetadas>> incorporando la estructura de grafo creada en el paso anterior.
        \end{enumerate}
\end{itemize}

\imagen{./img/memoria/conceptos/Taxonomy_Semi-Supervised_Methods}{Visualización de la taxonomía de los métodos de aprendizaje semi-supervisado. En la rama correspondiente a los métodos basados en grafo podemos observar las distintas fases de clasificación \bib{van2020survey}}{SSLTaxonomy}

\section{Supervised Learning}

También llamado \loc{classification}\footnote{A pesar que no solo trate problemas de clasificación} o \loc{inductive learning} (recordemos fig. \ref{fig:MachineLearningTypes}), el aprendizaje supervisado es aquel aprendizaje cuyas instancias de datos (usadas para que nuestro programa aprenda) están todas etiquetadas.

Según Christopher M. Bishop \et \bib{bishop2006pattern}, el objetivo último del aprendizaje supervisado es ser capaces de observar una variable $t$ (\loc{target}) junto con una variable de entrada $x$ y predecir el valor de $t$ para cualquier nuevo valor de $x$.

Para conseguir la predicción de nuevos datos debemos crear un modelo que va a ser <<entrenado>>, <<testeado>> y <<validado>>. Para conseguir datos para las tres fases dividiremos nuestro \loc{dataset} en tres grupos respectivamente. Con la intención de que el modelo tenga un alto acierto en sus predicciones debe estar bien entrenado, por lo que la mayor fracción de los datos se destinará a esta fase\footnote{Normalmente un 70\% de los datos se asigna a la fase de entrenamiento, aunque depende mucho del problema específico al el que nos enfrentemos}. Pero hay que tener cuidado, porque asignar un porcentaje demasiado alto de los datos a la fase de entrenamiento puede derivar en \loc{overfitting} en el modelo.

El \loc{overfitting} ocurre cuando un modelo se ha sobre-entrenado con unos datos, por que lo que a la entrada de nuevos datos (desconocidos) $x$, generará una predicción $t$ sesgada a los datos de entrenamiento. Para evitar esto, usamos otra fracción de los datos de entrada como fracción <<de control>>: los datos de validación. De este modo iremos comprobando la deriva de las predicciones entre los datos de entrenamiento y los datos de validación.

Ahora podremos controlar la fase de entrenamiento y parar dicho entrenamiento, valga la redundancia, cuando detectemos este sobre-ajuste. Podemos ver esto en la figura \ref{fig:Overfitting}.
Gracias al \loc{set} de validación, detectamos el momento en el que la red comienza a sobre-ajustarse. Esto no solo nos evita cometer errores en la fase de test, sino que mediante la eliminación de iteraciones inútiles sobre el modelo, disminuimos en gran cantidad el tiempo de entrenamiento.

\imagen{./img/memoria/conceptos/Overfitting}{Visualización de \loc{overfitting} en un entrenamiento de una \sigla{CNN} (red neuronal convolucional). Podemos observar en rojo el punto exacto en el que la red comienza a sobre-ajustarse. Este es el momento en el que debemos parar el entrenamiento.}{Overfitting}

En la imagen vemos que el valor del eje de ordenadas tenemos el valor de los costes sobre las iteraciones (\loc{epochs} en inglés). Veremos más sobre esto en el apartado de \loc{fine-tunning} e hiperparametrización de una red neuronal. Veamos ahora los distintos tipos de aprendizaje supervisado.

\subsection{Regression}

En la regresión, el objetivo es predecir un valor numérico y continuo. Uno de los usos principales de modelos de regresión es el relleno de espacios en los datos o la estimación de valores futuros. Por otro lado, la regresión también se puede utilizar para determinar relaciones casuales entre variables dependientes e independientes \bib{maulud2020review}.

En los modelos de regresión, las variables independientes predicen a las variables dependientes. El análisis de regresión estima la variable dependiente $y$ en base al rango de variables independientes $x$. En cuanto a los tipos de regresión, puede ser simple o múltiple.

\begin{itemize}
  \item \textbf{Regresión simple}: En las regresiones simples solo tenemos una variable independiente $y$. Se define la dependencia de la variable como $y = \beta_0 + \beta_1 x + \epsilon$. De forma gráfica, la regresión simple se muestra como una línea entre los puntos cuyo objetivo es minimizar el error cuadrático de las distancias entre dicha línea y los puntos. Es común que en estos modelos tengamos puntos atípicos que se sitúen lejos de la mayoría. Estos puntos se denominan \loc{outliers} y al distanciarse del resto, provocan desviaciones importantes en la regresión \bib{seldon_2021}.
  \item \textbf{Regresión múltiple}: El objetivo de los modelos múltiples es la predicción del conjunto de variables independientes $y$ según el conjunto de variables dependiente $x$. El modelo básico es $y = \beta_0 + \beta_1 x_1 + \cdots + \beta_m x_m + \epsilon$. La fórmula para determinar la matriz es:

        \begin{align*}
          \hat{\beta} & =\left(X^{T} X\right)^{-1} X^{T} y \quad \text { donde }                          \\
          \\
          \quad \beta & =\left[\begin{array}{c}
                                   \beta_{0} \\
                                   \beta_{1} \\
                                   \vdots    \\
                                   \beta_{m}
                                 \end{array}\right], X=\left[\begin{array}{ccccc}
                                                               1      & x_{11}  & x_{12}  & \cdots & x_{1 m} \\
                                                               1      & x_{21}  & x_{22}  & \cdots & x_{2 m} \\
                                                               \vdots & \vdots  & \vdots  & \vdots & \vdots  \\
                                                               1      & x_{n 1} & x_{n 2} & \cdots & x_{m}
                                                             \end{array}\right], Y=\left[\begin{array}{c}
                                                                                           Y_{1}  \\
                                                                                           Y_{2}  \\
                                                                                           \vdots \\
                                                                                           Y_{n}
                                                                                         \end{array}\right]
        \end{align*}

\end{itemize}

\subsection{Classification}

El segundo y último tipo de aprendizaje supervisado es también el más familiar. La clasificación consiste en etiquetar una variable discreta $y$ dada una variable de entrada $x$. Según el número de etiquetas disponibles para la clasificación hablamos de clasificación binaria (2 etiquetas) o multi-clase.

Aunque no listamos todos los métodos, a continuación se pueden observar los más ampliamente usados\bib{ranganathan2018encyclopedia}:

\begin{enumerate}
  \item \textbf{Árboles de decisión}: Los árboles de decisión son una forma de representar reglas sobre los datos de forma jerárquica con una estructura secuencial recursiva que particiona los datos. Los árboles de decisión se usan para aproximar funciones discretas. Un nodo hoja indica el valor de la etiqueta $y$, mientras que un nodo de decisión especifica una operación a realizar. La evaluación comienza evaluando el nodo raíz (un nodo de decisión) y moviéndonos hasta encontrarnos con un nodo hoja, con la etiqueta buscada. El algoritmo más común en la construcción de árboles de decisión es una extensión del algoritmo propuesto por J. Quinlan en 1993 \et \bib{quinlan1993building}: \sigla{ID3} (\loc{Iterative Dichotomiser} 3). El árbol se construye \loc{top-down} de forma recursiva con la técnica de <<divide y vencerás>>. Puedes ver el pseudocódigo a continuación.

        \begin{algorithm}[H]
          \caption{Algoritmo ID3 - TreeBuilding(X, Y)}

          \BlankLine
          \KwIn{Para un \loc{set} de entradas de entrenamiento $X$ y una lista de etiquetas correspondientes $Y$}

          \BlankLine

          $N \gets \text{Nodo raíz}$\\
          \If{$\forall \text{ muestra} = \text{clase } C$}{
            $\text{etiqueta N} = C$\\
            $\Return$\\
          }

          \BlankLine
          \If{$Y = \text{vacío}$}{
            $\text{etiqueta N} = \text{clase más común C en } X \text{(voto mayoritario)}$\\
            $\Return$\\
          }

          \BlankLine
          $y \gets \text{El atributo que mejor clasifica ejemplos donde } y \in Y$\\
          $\text{etiqueta N} \gets y$\\

          \ForAll{$v \in y$}{
            $\text{Haz crecer una rama desde N con condición } y = v$\\
            $X_v \gets \text{\loc{subset} de instancias en Y con } y = v$\\
            \If{$X_v = \text{vacío}$}{
              $\text{añade un nodo hoja etiquetado con la clase más común en X}$\\
            }
            \Else{
              $\text{añade el nodo generado por } TreeBuilding(X_v, Y - v)$\\
            }
          }

        \end{algorithm}

  \item \textbf{\loc{Bagging} y \loc{boosting}}: Es una técnica de ensamblado que combina varios métodos de \loc{machine learning} en un único modelo predictivo en orden de disminuir la varianza (\loc{bagging}) o el \loc{bias(boosting)}.

        El \loc{bagging (Bootstrap Aggregating)} comienza creando muestras aleatorias del \loc{set} de entrenamiento. Tras esto, construye un clasificador para cada muestra. Finalmente, se combinan los resultados de los clasificadores y comienza una votación de mayoría. Al construir estos modelos al mismo tiempo, consideramos a Bagging un método de ensamblado paralelo. Al aumentar el tamaño del \loc{set} de entrenamiento, se disminuye la varianza del modelo final \bib{bauer1999empirical}.

        El \loc{boosting} por otro lado se compone de dos pasos. En el primero usa \loc{subsets} del \loc{set} de entrenamiento para producir modelos con rendimiento medio. Tras esto estimula el rendimiento combinándolos usando el voto mayoritario. En el \loc{boosting}, la creación de \loc{subsets} no es aleatoria y depende del rendimiento de los modelos anteriores.

        La principal diferencia entonces entre los dos, es que \loc{bagging} aprende el \loc{dataset} completo de forma paralela mientars que \loc{boosting} aprende usando los resultados de los modelos anteriores. \loc{Boosting} muestra una mejor \loc{accuracy} que \loc{bagging} \bib{quinlan1996bagging}, pero también tiene a producir \loc{overfitting} en los modelos.

  \item \textbf{\loc{Random Forest}}: El \loc{random forest} también se puede usar en tareas de regresión. El principio que se sigue es que un conjunto de clasificadores <<débiles>> se puede unir para crear un clasificador <<fuerte>>. En este caso tenemos un \loc{ensemble} de árboles de decisión que funciona mejor que \loc{bagging} y \loc{boosting} tanto en \loc{accuracy} como en \loc{overfitting}. Cada árbol del \loc{ensemble} tiene un \loc{set} de entrenamiento distinto. Debemos tener en cuenta que si necesitamos una descripción de las relaciones existentes entre los datos, los \loc{random forest} no son la mejor opción, ya que al tener un conjunto de árboles, se hace difícil la compresión de la estructura general.

  \item \textbf{\loc{Support Vector Machines}} (\sigla{SVM}): Según Van Engelen \et \bib{van2020survey} un \sigla{SVM} es un clasificador que intenta buscar la frontera de decisión que maximice el margen, que a su vez se define como la distancia entre la frontera de decisión y los puntos cercanos a ella\footnote{A veces el margen también se refiere a la zona delimitada por la frontera de decisión en la que caen los puntos}.

        Los \sigla{SVM} también están presentes en la regresión. En el caso de la clasificación, tenemos un conjunto de puntos en un espacio de dimensión $N$. Cada \loc{set} perteneciendo a una de las posibles clases, el \sigla{SVM} busca los planos separados que maximicen los margenes entre los \loc{sets} de datos. A la hora de clasificar un dato, separamos dos planos y calculamos el error cuadrático de los puntos a dichos planos. En algunas ocasiones, los planos pueden no ser linealmente separables; en estos casos, debemos aumentar el número de dimensiones hasta que lo sean. Para esto se usa lo que se denomina función \loc{kernel} \bib{busuttil2003support} \[K(x,y)=\langle f(x), f(y) \rangle \] donde $x$ e $y$ son las entradas de dimensión $n$, y $f$ es un mapa de paso de dimensión-$n$ a dimensión-$m$. Normalmente nos encontraremos con que $m$ es un número mucho mayor a $n$.

  \item \textbf{\loc{Naive Bayes}}: Este clasificador probabilístico se basa en el teorema de Bayes y asume que todas las características están independientemente condicionadas por la etiqueta de la clase \bib{murphy2006naive}. Aunque esto no suele ocurrir, el modelo resultante funciona sorprendentemente bien, a veces compitiendo con técnicas mucho más sofisticadas \bib{rish2001empirical}. Este modelo ha probado ser muy útil en tareas de clasificación de texto y diagnóstico médico, entre otros. En \bib{domingos1997optimality} se prueba que \loc{naive Bayes} funciona de forma óptima en problemas con un alto grado de dependencia entre características.

  \item \textbf{Redes Neuronales}: Por último, tenemos las redes neuronales. Las redes neuronales ocupan la mayoría de la literatura sobre inteligencia artificial y \loc{machine learning} en la actualidad. Una red neuronal es un conjunto de neuronas artificiales colocadas en capas. Cada capa tiene la tarea de extraer características de los datos de entrada, actualizar sus pesos y <<pasar>> información a las siguientes capas.

        Una neurona es una función $f_j$ con una entrada $x = (x_1, \ldots , x_d)$ y un vector de pesos $w_j = (w_{j,1}, \ldots , w_{j,d})$, junto con un \loc{bias} $b_j$ y asociado a una función de activación $\phi$ \bib{bishop1994neural}. La fórmula completa de está función es \[y_j = f_j(x) = \phi (\langle w_j, x \rangle + b_j )\]

        Existen numerosas funciones de activación en una red neuronal, algunas son:
        \begin{itemize}
          \item Función identidad o lineal \[\phi(x) = x\]
          \item \loc{Binary Step} \[\phi(x) = \lbrace\begin{array}{ll}0 & \text{ para } x<0 \\ 1 & \text{ para } x \geq 0\end{array}\]
          \item Función sigmoide \[\phi(x) = \frac{1}{1 + \exp(-x)}\]
          \item Tangente hiperbólica \[\phi(x) = \frac{\exp(2x) -1 }{\exp(2x) + 1}\]
          \item \sigla{ReLU} (\loc{Rectified Linear Unit}) \[\phi(x) = \max(0, x)\]
          \item \loc{Leaky} \sigla{ReLU} \[\phi(x) = max(0.1 \cdot x,x)\]
          \item \sigla{ELU} (\loc{Exponential Linear Unit}) \[\phi(x) = \lbrace\begin{array}{ll}x & \text{ para } x \geq 0 \\ \alpha(\exp(x) - 1) & \text{ para } x < 0\end{array}\]
          \item Función softmax: descrita como una combinación de múltiples sigmoides, calculamos su salida con \[\phi(x_i) = \frac{exp(x_i)}{\sum_j exp(x_j)}\] siendo $x$ el conjunto de las salidas de una neurona en un problema multiclase.
        \end{itemize}

        Tanto la función de \loc{binary step} como la función de identidad (ambas funciones lineales) no permiten \loc{backpropagation} ya que la derivada de la función es una constante y no tiene relación alguna con la variable de entrada x (no aporta datos adicionales) \bib{hinton2006unsupervised}.

        Por otro lado, en regresión se usan funciones de activación lineales, mientras que usaríamos sigmoides en clasificación binaria, o softmax en clasificación multietiqueta.

        Una vez tenemos nuestra función de activación elegida, podemos calcular la salida de la red dada una variable de entrada $x$. Y una vez calculada la salida de la red, podemos comparar el resultado $y$ con la etiqueta de \loc{ground truth} correspondiente con dicha entrada. Según sea igual o no, modificaremos el vector de pesos de nuestra neurona.

        Repetiremos este proceso hasta que el \loc{accuracy} de la neurona (o la red de neuronas) sea superior al \loc{threshold} buscado \bib{ranganathan2018encyclopedia}.

        Podemos medir el \loc{accuracy} de una neurona dividiendo el número de predicciones correctas entre el número total de predicciones \bib{flach2019performance}. Pero el \loc{accuracy} no es el único método de medida de acierto en las redes neuronales. También tenemos la precisión, el \loc{recall}, el \loc{F-measure}, la especificidad, el \loc{fallout} o la Coeficiente de Correlación de \loc{Mathew} (\sigla{MCC}) \bib{chicco2020advantages}.

        Con
        \begin{align*}
          tp = \loc{true positives}  \\
          tn = \loc{true negatives}  \\
          fp = \loc{false positives} \\
          fn = \loc{false negatives}
        \end{align*}

        \begin{itemize}
          \item \loc{Accuracy}: $Acc = \frac{tp + tn}{tp + tn + fp + fn}$
          \item Precisión: $P = \frac{tp}{tp + fp}$
          \item \loc{Recall}: $R = \frac{tp}{tp+ fn}$
          \item \loc{F-measure}: $F = \frac{2P \cdot R}{P + R}$
          \item Especificidad: $S_p = \frac{tn}{tn + fp}$
          \item \loc{Fallout}: $\frac{fp}{tn + fp}$
          \item Coeficiente de Correlación de \loc{Mathew}: $\sigla{MCC} = \frac{tp \cdot tn - fp \cdot fn}{\sqrt{(tp + fp)(tn + fn)(tp + fn)(tn + fp)}}$
        \end{itemize}
\end{enumerate}

\section{Deep Learning}

Hemos visto en el último apartado las características de una red neuronal de forma individual: como se compone, que tipos de funciones de activación tenemos y como podemos evaluar y medir la salida de una neurona.

Las redes neuronales más básicas: \sigla{FFNN} (\loc{Feed Forward Neural Netowrks}) y Perceptrones, se componen únicamente de una capa de entrada y salida, con ocasionalmente una o más capas ocultas entre ambas. El método para entrenar estas redes suele ser el \loc{backpropagation}.

El término \loc{backpropagation} viene tras ser empleado por \loc{Rosenblatt} (1962) \bib{block1962analysis} a la hora de intentar generalizar el entrenamiento de un perceptrón a múltiples capas ocultas. No fué muy exitoso hasta que \loc{Rumelhart} y \loc{Williams} (1986) \bib{rumelhart_hinton_williams_1986} extendieron la idea y la hicieron popular entre investigadores \bib{rumelhart1995backpropagation}. La idea del \loc{backpropagation} es minimizar el error entre la salida correcta e incorrecta mediante el \loc{gradient descent}. Para esto necesitamos calcular las derivadas parciales de nuestras funciones de activación \footnote{Recordemos que solo las funciones de activación no lineales pueden ser usadas para el \loc{backpropagation}, ya que la derivada de una función lineal es una constante}. Calculamos la salida de la derivada en el \loc{forward pass}, y con el resultado obtenido, realizamos un \loc{backward pass}, con el que propagamos y actualizamos los pesos de la red.

Esto ahora nos parece básico, pero fue una <<revolución>> en su momento y es la base principal del \loc{deep learning}. Pero, el \loc{deep learning} no solo trata el aprendizaje supervisado, (también tenemos \loc{deep reinforcement learning}, \loc{unsupervised learning}\footnote{Una de las redes neuronales en \loc{unsupervised learning} más habladas en la literatura son las redes \sigla{GAN} (\loc{Generative Adversarial Neural Networks}). Estas redes usan la estructura de discriminador-generador \bib{GenerativeAdversarial} para extraer información de los datos de entrada} y \loc{semi-supervised learning}). Por simplificar vamos a tratar solo redes neuronales de aprendizaje supervisado o \sigla{DNN} (\loc{Deep Neural Networks}). Una lista extensa de redes neuronales se puede ver en \bib{typesann}.

Las \loc{deep neural networks} (\sigla{DNN}) se clasifican en dos tipos principales: Redes Neuronales Recurrentes (\sigla{RNN}) y Redes Neuronales Convolucionales (\sigla{CNN}). Se diferencia de las redes neuronales artificiales <<clásicas>> (\sigla{ANR}) \footnote{Como \sigla{FNNN} o perceptrón} en que en vez de tener una capa de entrada seguida de una o más capas escondidas, con una capa de salida a continuación; las \sigla{DNN} tienen más de una capa entre la salida y la entrada, de ahí que se denominen profundas \bib{typesann}.

\imagen{./img/memoria/conceptos/RNN_CNN}{Estructura de una red \sigla{RNN} y \sigla{CNN}}{RNN_CNN}

En la figura \ref{fig:RNN_CNN}, se puede observar la estructura de los dos tipos mencionados. La red recurrente debe su nombre a las neuronas que están conectadas consigo mismas (neuronas en azul).

Las redes neuronales convolucionales son más complejas y su particularidad, como veremos más en profundidad en el siguiente apartado, es la extracción de características y reducción de la dimensionalidad. Vemos que la capa de entrada (en amarillo) tiene 5 neuronas, y que en las siguientes capas, el número de neuronas se va reduciendo hasta llegar a dos en la capa justo anterior a la oculta (en verde). Esto se produce mediante la convolución o el \loc{pooling}. Vamos a estudiar estas dos redes y sus términos con un poco más de profundidad a continuación.

\begin{itemize}
  \item \textbf{\sigla{RNN}}: Las Redes Recurrentes son redes que tuvieron su auge en investigación en los años 90. \loc{Fausett} (1994) \bib{fausett1994fundamentals} las define como redes neuronales con conexiones \loc{feedback} (retroalimentación). Ejemplos de estas redes son las redes \sigla{BAM} (\loc{Bidirectional associative memory}), redes \loc{Hopfield} y máquinas de \loc{Boltzmann} \bib{medsker1999recurrent}.

        La característica principal de las redes recurrentes es que tienen un estado que mantienen entre distintas iteraciones de la red. Las neuronas no solo reciben información de la capa anterior si no que también reciben información de si mismas y de la iteración anterior \bib{elman1990finding}. Por esta razón, el orden con el que <<alimentamos>> datos a la red es importante y puede cambiar la salida generada de forma radical. Esta característica las hace muy útiles con formatos de datos como vídeo o audio \footnote{Aunque también podemos tratar texto o imagen como concatenación de letras o píxeles en el tiempo}. Su principal aplicación es el avance y completado de información, como por ejemplo el autocompletado de texto.  En \bib{rodriguez1999recurrent} podemos ver un ejemplo de una \sigla{RNN} aplicada para enseñar a la red a contar.

  \item \textbf{\sigla{CNN}}: Y llegamos a las redes convolucionales. Introducidas por \loc{Le Cun} (1998) \bib{le1989handwritten}, estas redes son uno de los tópicos más hablados en la literatura actual en el mundo del \loc{machine learning} y la inteligencia artificial. Estas redes se usan en muchísimas aplicaciones y dominios, sobre todo en procesamiento de vídeo e imagen.

        Las redes convolucionales tienen una estructura muy diferente a cualquier otra red neuronal (figura \ref{fig:CNN_Arquitecture}). Se componen de capas de convolución, capas de \loc{subsampling} y capas <<\loc{fully-connected}>>.

        \imagen{./img/memoria/conceptos/CNN_Arquitecture}{Estructura de una \sigla{CNN}. Figura de \loc{Le Cun} \et \bib{lecun1998gradient}}{CNN_Arquitecture}

        A continuación vamos a hablar de filtros o \loc{kernels}, \loc{pooling}, \loc{padding}, \loc{stride}, \loc{ResNet}, entre otros términos.

        \begin{enumerate}
          \item \textbf{Extracción de características o convolución}: En esta fase se busca reducir la dimensionalidad de la entrada manteniendo las características espaciales de los datos. De esta forma no perdemos información y es más fácil procesarla en las siguiente capas. En redes neuronales tradicionales, transformaríamos una entrada (imagen o vídeo) en un vector de dimensión uno.

                Al hacer esto perderíamos información de formas en la imagen, o de movimientos de objetos o personas en los vídeos. Por esa razón, la extracción de características de una imagen se hacía antes de forma manual en la fase de preparación de los datos.

                Para eliminar esta fase manual, las \sigla{CNN} actúan directamente en matrices de datos multidimensionales (o tensores \footnote{Un tensor es un objeto algebraico que representa un espacio vectorial. Puede mapear vectores y matrices multidimensionales \bib{wiki:tensor}}), en vez de actuar sobre vectores. Pero, ¿cómo extraemos información de un tensor?

                Para extraer información de un tensor manteniendo sus características espaciales vamos a usar \loc{kernels} o filtros.

                Un filtro es un tensor con las mismas dimensiones que el tensor de entrada de la red, pero con tamaños mucho menores. \pe: si tenemos como entrada una imagen de $(200x200)$ píxeles, tendremos un filtro de dos dimensiones, por ejemplo, de $(3x3)$ píxeles. Si en vez de una imagen, estamos clasificando un vídeo con 10 \loc{frames} $(10x200x200)$ tendremos un filtro que por ejemplo puede tener el tamaño $(2x3x3)$, siendo 2 el número de \loc{frames}.

                Una vez tenemos nuestro tensor de entrada y nuestro \loc{kernel}, podemos iniciar el proceso de convolución. Para hacer esto, vamos a <<mover>> nuestro \loc{kernel} por nuestro tensor de entrada, generando un <<mapa de características>>. Veamos un ejemplo:

                \imagen{./img/memoria/conceptos/Kernel}{Ejemplo de convolución con \loc{kernel} $3x3$ sin \loc{strading} ni \loc{padding}}{Kernel}

                Vemos en la figura \ref{fig:Kernel} que tenemos un tensor bidimensional (\pe una imagen) de tamaño $(5x5)$ con un \loc{kernel} de tamaño $(3x3)$. El mapa de características resultante tiene un tamaño de $(3x3)$\footnote{Da la casualidad de que el tamaño de la salida es igual al tamaño del kernel, pero no es la norma. Si tuviéramos una entrada de $(5x7)$ obtendríamos una salida de $(3x5)$}.

                En este caso no hemos tenido ningún problema y hemos podido <<encajar>> nuestro \loc{kernel} en la matriz perfectamente. Esto no siempre es así, ya que si queremos adaptarnos a cualquier tipo de entrada, es posible que tengamos tamaños cuyo \loc{kernel} no <<encaje>> de forma perfecta.

                Por ejemplo, si nuestra matriz fuera de $(4x4)$ en vez de $(5x5)$, tendríamos que para el tercer cálculo, nuestro \loc{kernel} se sitúa fuera de la matriz (en el lado derecho). Para solucionar este problema usamos \loc{padding} o \loc{stride}.

                \begin{itemize}
                  \item El \loc{padding} se usa para añadir <<información>> en los bordes de nuestro tensor y así mantener el tamaño de salida deseado. Podemos elegir añadirlo en todos los bordes o solo en algunos. El valor óptimo del \loc{padding} es $0$. Esto es porque toda información que añadamos a los bordes, <<contamina>> la información importante ubicada en el tensor de entrada \bib{o2015introduction}.

                  \item El \loc{stride} por otro lado indica la cantidad de unidades que movemos nuestro \loc{kernel} sobre nuestra entrada en cada iteración de la convolución. Valores comunes de \loc{stride} son $2$ o $3$ \bib{gu2018recent}. Tenemos que tener cuidado aquí, porque con un \loc{stride} demasiado alto, podemos saltarnos extracciones de características importantes de nuestro tensor.
                \end{itemize}

                Podemos calcular el tamaño de salida con la siguiente fórmula \bib{o2015introduction}: \[\delta = \frac{D + 2p - K}{s} + 1\] donde $D$ es un vector de tamaño $d$ con las dimensiones de nuestro tensor de entrada, $K$ es un vector de tamaño $d$ con las dimensiones del \loc{kernel}, y $p$ y $s$ son los valores de \loc{padding} y \loc{stride} respectivamente. La salida será un número $\delta$. Si el número es un entero, entonces la convolución será correcta.

                Así en nuestro caso $\delta = [\frac{5 + 2 \cdot 0 - 3}{1} + 1, \frac{5 + 2 \cdot 0 - 3}{1} + 1] = [3, 3]$. Como vemos, en el proceso de convolución, <<alteramos>> las dimensiones del tensor de entrada con la finalidad de extraer las características espaciales del mismo.

          \item \textbf{\loc{Pooling}}: Muy similar a la fase de convolución, el \loc{pooling} reduce el tamaño del mapa de características. El objetivo es disminuir la capacidad computacional necesaria para procesar gran cantidades de datos \bib{cui2017kernel}. Hay dos tipos de \loc{pooling} principales: \loc{Max Pooling} y \loc{Average Pooling}. El primero devuelve el valor máximo de la <<porción>> del tensor cubierta por el \loc{kernel} mientras que el segundo devuelve la media de todos los valores en dicha <<porción>>. \loc{Max pooling} funciona normalmente mejor que \loc{average pooling} porque no solo lleva a cabo la labor de reducción de la dimensionalidad, sino que también actúa como mecanismo de eliminación de ruido. \footnote{Denotar que lo importante del \loc{kernel} en el \loc{pooling} son sus dimensiones ya que no vamos a realizar operaciones con él}.

          \item \textbf{Capa \loc{fully connected}}: Una vez hemos extraído las características necesarias de nuestro tensor de datos, hemos terminado con un tensor con dimensiones reducidas. Esta fase se ve muy bien gráficamente en la figura \ref{fig:RNN_CNN}. Las capas de color rosa son las capas en las que realizamos la convolución y el \loc{pooling}. El tensor resultante debe ahora sí, ser convertido en un vector (tensor de dimensión uno), ya que este es la entrada ahora de una capa \loc{fully connected}. Este proceso se denomina \loc{flatten}.

                Las capas \loc{fully connected} se asemejan mucho a estructuras tradicionales de una red neuronal, con la diferencia de que las neuronas que forman esta capa aplican una transformación lineal del vector de entrada primero, seguido de una transformación <<no lineal>>.

                La salida de esta capa se calcula como \[
                  y_{j k}(x)=f\left(\sum_{i=1}^{n} w_{j k} x_{i}+w_{j 0}\right)
                \] donde $w_0$ es el \loc{bias}, $w$ nuestra matriz de pesos, $x$ el vector de entrada y $f$ la función de activación no lineal.

                El nombre de esta capa \footnote{También se suele llamar capa densa} se debe a que las neuronas están totalmente conectadas entre si entre las distintas capas (no entre neuronas de la misma capa ni consigo mismas) \bib{huang2017densely}.

                La salida de la capa \loc{fully conneted} será la salida que produce la función de activación no lineal que se aplica tras las funciones lineales. Esta función puede ser una función \loc{softmax} para clasificación multiclase o puede ser una sigmoide para otro tipo de salida. Por ejemplo, en este proyecto, se ha usado una \loc{fully connected} con \loc{softmax} para clasificar los signos y una \loc{fully connected} con sigmoide para extraer un vector de poses de gestos en un vídeo. Puedes avanzar a la sección <<Aspectos relevantes>> para más información.
        \end{enumerate}

        Existen numerosas arquitecturas de redes neuronales convolucionales que han demostrado ser muy útiles en la resolución de distintos problemas. Algunas son: \sigla{AlexNet} \bib{krizhevsky_sutskever_hinton_2012}, \sigla{LeNet}\bib{lenet}, \sigla{VGGNet} \bib{VGGNet}, \sigla{GoogLeNet} \bib{GoogLeNet}, \sigla{ZFNet} \bib{ZFNet} o \sigla{ResNet} \bib{ResNet}.
\end{itemize}

Todas estas no son ni mucho menos todas las redes neuronales del campo del \loc{deep learning}. Cada pocos meses se publica un \loc{paper} que muestra estructuras nuevas con oportunidades futuras impresionantes. En la actualidad, otro de los modelos de \loc{deep learning} que más atención (nunca mejor dicho) genera, son los modelos \loc{transformers}, expuestos por primera vez en el famoso \loc{paper} <<\loc{Attention is all you need}>>, parte de un libro de (2017) \bib{attention}. Estos modelos usan el llamado <<mecanismo de atención>> que da pesos diferentes a las distintas partes de nuestro dato de entrada (llamados \loc{tokens}). Los principales campos en los que se usan los \loc{transformers} son el campo del \loc{natural language processing} (\sigla{NLP}) y el campo de \loc{computer vision} (\sigla{CV}).

\textbf{Nota del autor}: Los \loc{transformrs} se alejan un poco del tema principal de este proyecto, pero invito a leer el fantástico \loc{paper} y descubrir sobre los modelos que usan esta red y que están revolucionando el mundo del \loc{deep learning} (\pe: \sigla{GPT-3} o \sigla{DALL-E})

\section{Data Augmentation}

Las redes neuronales convolucionales, como hemos visto en los apartados anteriores, tienen a funcionar
extraordinariamente bien en tareas de clasificaicón de video e imagen, pero, en contrapartida, necesitan gran cantidad de datos para evitar \loc{overfitting} \bib{shorten2019survey}.

Desgraciadamente, son muchas las ocasiones en las que no podemos usar datos de entrenamiento suficientes para evitar \loc{overfitting}, como en el caso de datos médicos. En estos casos, aplicamos la aumentación de datos.

\loc{Data augmentation} o aumentación de los datos, agrupa un conjunto de técnicas con las cuales buscamos extender el conjunto de datos de entrenamiento de nuestros modelos, en caso de que sean insuficientes.

Las principales técnicas de aumentación de datos son la transformación geométrica, las transformaciones en el espacio de color, aplicación de filtros \loc{kernel} (como hemos visto en la convolución), mezcla de distintas imágenes o videos, borrado aleatorio, aumentación del espacio de características, transferencia de estilo y redes generativas adversarias (\sigla{GANs}).

La aumentación de datos busca un acercamiento al \loc{overfitting} desde la raíz principal del problema: el \loc{dataset}. Esto es asumiendo que el \loc{dataset} tienen datos que pueden ser aumentados.

Estas aumentaciones artificales inflan el \loc{dataset} en tamaño de dos formas: por deformación de datos (\loc{data warping}) o por \loc{oversampling} (sobremuestreo).

Las deformaciones de datos transforman los datosa existentes preservando su etiqueta. Algunos tipos son:

\begin{enumerate}
  \item Transformación geométrica y/o de color
  \item Eliminación parcial aleatoria de datos espaciales
  \item Transferencia de estilo (mediante redes adversarias generativas (\sigla{GANs}))
\end{enumerate}

Por otro lado, el supersampleo consiste en mantener los datos actuales y añadir nuevas instancias al \loc{set} de entrenamiento. La aplicación de \loc{oversampling} y \loc{data warping} no es una dicotomía mutuamente exclusiva.

Podemos observar en la figura \ref{fig:dataAugmentation} un esquema de la mayoría de técnicas de aumentación de datos.

\imagen{./img/memoria/conceptos/dataAugmentation}{Ejemplo de \loc{data augmentation} aplicando \loc{adversarial neural netowkrs}, más concretamente \loc{CycleGANs}. Extraido de \bib{face_CycleGANs}}{dataAugmentation}

Lo que hace el reconocimiento de imágenes y video un problema tan complejo en \loc{deep learning} es que el modelo de reconocimiento debe sobrellevar problemas del punto de visión, la luz, la oclusión ambiental, el color del fondo, la escala de los elementos, entre otros. La aumentación de datos consiste en internalizar estas pequeñas variaciones de movimeiento y color en los datos, de tal modo que, una vez entrenado el modelo, funcione en todas las situaciones posibles.

Pero el \loc{data augmentation} no es la única técnica que se puede aplicar para evitar \loc{overfitting}. Otra técnica bastante común (y que nosotros hemos aplicado) es el denominado \loc{batch normalization}. El \loc{batch normalization} es una técnica de regularización de los datos que normaliza los \loc{sets} de las capas de activación de una red neuronal. Esta normalización funciona restando la media de cada activación y dividiendo entre la desviación estándar de todos los valores del \loc{batch} \bib{shorten2019survey}.
